{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:03.957163Z",
     "start_time": "2024-10-12T13:54:03.953142Z"
    }
   },
   "source": [
    "#imports\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import config\n",
    "\n",
    "DATASET_1 = 'Data_1'\n",
    "DATASET_2 = 'Data_2'\n",
    "CURRENT_DATASET = DATASET_2\n",
    "SCENARIOS = ['Ulds_scenario_1', 'Ulds_scenario_2a', 'Ulds_scenario_2b']\n",
    "\n",
    "PATH = './Data/' + CURRENT_DATASET\n",
    "INPUT_PATH = PATH + '/2_AeJobs'\n",
    "OUTPUT_PATH = PATH + '/3_AeResults'\n",
    "\n",
    "URL = config.BACKEND_SERVER_URL"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:04.305563Z",
     "start_time": "2024-10-12T13:54:04.302447Z"
    }
   },
   "source": [
    "def readJson(filePathImport):\n",
    "    #Read file in\n",
    "    with open(filePathImport) as json_file:\n",
    "        job_json = json.load(json_file)\n",
    "        return job_json"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:04.411010Z",
     "start_time": "2024-10-12T13:54:04.407095Z"
    }
   },
   "source": [
    "def writeJson(filePathExport, jsonFile):\n",
    "    with open(filePathExport, 'w', encoding='utf-8') as f:\n",
    "        json.dump(jsonFile, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:04.820662Z",
     "start_time": "2024-10-12T13:54:04.816514Z"
    }
   },
   "source": [
    "def createOutputFolderIfNotExists(path):\n",
    "    isExist = os.path.exists(path)\n",
    "    if isExist:\n",
    "        shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(path)\n",
    "    print(\"The new directory is created!\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def read_concatenate_jobs(batch, input_path: str):\n",
    "    jobs = []\n",
    "    for f in batch:\n",
    "        input_path_full = input_path  + '/' + f\n",
    "        try:\n",
    "            job = readJson(input_path_full)\n",
    "            jobs.append(job)\n",
    "        except:\n",
    "            print(\"Could not read file! \" + input_path_full)\n",
    "            return jobs\n",
    "    return jobs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:05.246792Z",
     "start_time": "2024-10-12T13:54:05.242295Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def _store_results(r, output_path: str):\n",
    "    assessment_results = r.json()\n",
    "    for assessment_result in assessment_results:\n",
    "        output_path_full = output_path + '/' + assessment_result[\"label\"]\n",
    "        writeJson(output_path_full, assessment_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:05.591855Z",
     "start_time": "2024-10-12T13:54:05.588596Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def execute_jobs_parallel(batch_size: int, input_path: str, output_path:str):\n",
    "    createOutputFolderIfNotExists(output_path)\n",
    "    file_names = list(fname for fname in os.listdir(input_path) if fname.endswith('.json'))\n",
    "\n",
    "    l_index = 0\n",
    "    r_index = batch_size\n",
    "    current_batch = file_names[l_index:r_index]\n",
    "\n",
    "    pbar = tqdm(total=len(file_names))\n",
    "\n",
    "    while current_batch:\n",
    "        jobs = read_concatenate_jobs(current_batch, input_path)\n",
    "\n",
    "        r = requests.post(URL, json=jobs)\n",
    "\n",
    "        if r.ok:\n",
    "            _store_results(r, output_path)\n",
    "        else:\n",
    "            print(\"Failure \" + r.text)\n",
    "\n",
    "        l_index, r_index = r_index, r_index + batch_size\n",
    "        current_batch = file_names[l_index:r_index]\n",
    "        pbar.update(batch_size)\n",
    "    pbar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:06.363869Z",
     "start_time": "2024-10-12T13:54:06.358555Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T13:54:06.984309Z",
     "start_time": "2024-10-12T13:54:06.978206Z"
    }
   },
   "source": [
    "def executeAeJob(file_path_input, file_path_output):\n",
    "    aeJob = 0\n",
    "    try:\n",
    "        aeJob = readJson(file_path_input)\n",
    "    except:\n",
    "        print(\"Could not read file! \" + file_path_input)\n",
    "        return\n",
    "    \n",
    "    r = requests.post(URL, json=aeJob)\n",
    "    \n",
    "    if r.ok:\n",
    "        writeJson(file_path_output, r.json())\n",
    "    else:\n",
    "        print(\"Failure \" + r.text)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T14:19:38.782373Z",
     "start_time": "2024-10-12T13:54:07.993172Z"
    }
   },
   "source": [
    "for scenario in SCENARIOS:\n",
    "    execute_jobs_parallel(40, INPUT_PATH + '/' + scenario, OUTPUT_PATH + '/' + scenario)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9720it [08:28, 19.13it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9720it [08:31, 19.00it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9720it [08:30, 19.03it/s]                          \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
